{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Random Forest.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"yh7MlfoMRAbn"},"source":["# Random Forest"]},{"cell_type":"markdown","metadata":{"id":"ESrCRnv2RO1T"},"source":["## Data Preparation"]},{"cell_type":"code","metadata":{"id":"-JXX5OPCRCzC"},"source":["# Import Necessary Packages and Mount the Drive\n","!pip install scikit-learn --upgrade\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt \n","from math import sqrt\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n","from sklearn.model_selection import KFold, RandomizedSearchCV\n","pd.set_option('display.max_columns', None)\n","from preprocessing.preprocessing import one_hot_encode_days, one_hot_encode_months, time_differencing, split_and_scale, sin_cos_waves, sliding_windows\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=False)\n","\n","%cd '/content/gdrive/MyDrive/ECSE_552/Project'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d0_bQpuLRCus"},"source":["# Import the dataset\n","df = pd.read_csv('data/ON_demand_weather_17-20.csv', index_col=0)\n","\n","# Do all the preprocessing required\n","# Remove weather stations and market demand columns\n","df.drop(['Market Demand',\n","         'toronto_Temp (C)',\n","         'hamilton_Temp (C)',\n","         'ottawa_Temp (C)',\n","         'kitchener_Temp (C)',\n","         'london_Temp (C)',\n","         'windsor_Temp (C)'], axis=1, inplace=True)\n","\n","# Apply scaling if desired and split dataset into train, validation, and testset\n","scaler = None  # Define the type of scaler, options are 'min-max', 'standard', and None\n","columns_to_scale = ['Ontario Demand', 'Weighted Average Temp (C)']  # Define columns to be scaled, add time-differenced column if applicable\n","target_column = columns_to_scale[0]  # Define target column (required to allow unscaling later), change to time-differenced column if applicable\n","vali_set_start_date='2019-07-01'  # First day of validation set\n","test_set_start_date='2020-01-01'  # First day of test set\n","\n","train_df, vali_df, test_df, target_scaler = split_and_scale(df,\n","                                                            scaler=scaler,\n","                                                            columns_to_scale=columns_to_scale,\n","                                                            target_column=target_column,\n","                                                            vali_set_start_date=vali_set_start_date,\n","                                                            test_set_start_date=test_set_start_date)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u-QLZeRQRwtf"},"source":["## Model Training and Evaluation"]},{"cell_type":"markdown","metadata":{"id":"d4qqPADQR0U8"},"source":["#### 1Hour Prediction"]},{"cell_type":"code","metadata":{"id":"80agappESj6D"},"source":["# Prepare Sliding Window for 1H Prediction\n","window_size = 18\n","flatten = True\n","output_window_size = 1\n","perform_feature_shift = False\n","\n","# Sliding windows\n","# note that the function removes the 'Date' column (not numeric)\n","x_train, y_train = sliding_windows(df=train_df, window_size=window_size, target_column=target_column, flatten=flatten, output_window_size=output_window_size, perform_feature_shift=perform_feature_shift)\n","x_vali, y_vali = sliding_windows(df=vali_df, window_size=window_size, target_column=target_column, flatten=flatten, output_window_size=output_window_size, perform_feature_shift=perform_feature_shift)\n","x_test, y_test = sliding_windows(df=test_df, window_size=window_size, target_column=target_column, flatten=flatten, output_window_size=output_window_size, perform_feature_shift=perform_feature_shift)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Kf_mM9xRCp4"},"source":["# Train random forest\n","model = RandomForestRegressor(n_estimators=100)\n","# model = RandomForestRegressor(n_estimators=100, min_samples_split=3, min_samples_leaf=2, max_depth=50)\n","\n","model.fit(x_train, y_train)\n","\n","# R2 score\n","print(\"RF train R^2-Score: %0.3f\" % model.score(x_train, y_train))\n","print(\"RF valid. R^2-Score: %0.3f\" % model.score(x_vali, y_vali))\n","\n","# RMSE (scaled, if applicable)\n","y_train_pred = model.predict(x_train)\n","y_vali_pred = model.predict(x_vali)\n","\n","print(\"RF train RMSE: %0.3f\" % sqrt(mean_squared_error(y_train_pred, y_train)))\n","print(\"RF valid. RMSE: %0.3f\" % sqrt(mean_squared_error(y_vali_pred, y_vali)))\n","\n","if scaler is not None:\n","  y_train_unscaled = target_scaler.inverse_transform(y_train)\n","  y_vali_unscaled = target_scaler.inverse_transform(y_vali)\n","  y_train_pred_unscaled = target_scaler.inverse_transform(y_train_pred.reshape(-1, 1))\n","  y_vali_pred_unscaled = target_scaler.inverse_transform(y_vali_pred.reshape(-1, 1))\n","  print(\"RF train RMSE (unscaled): %0.3f\" % sqrt(mean_squared_error(y_train_pred_unscaled, y_train_unscaled)))\n","  print(\"RF valid. RMSE (unscaled): %0.3f\" % sqrt(mean_squared_error(y_vali_pred_unscaled, y_vali_unscaled)))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WhtYJaYCRCmL"},"source":["# Plot Performance\n","samples = [4,81,854,1701,3621]\n","for i in samples:\n","  plt.figure(figsize=(10,2))\n","  plt.plot(y_vali_pred[i], label='pred')\n","  plt.plot(y_vali[i], label='true')\n","  plt.legend()\n","  plt.xlabel('hours')\n","  plt.ylabel('Demand in MW')\n","  plt.title('Random Forest prediction example on validation set')\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"34pXPDq1b8fG"},"source":["##### Testing"]},{"cell_type":"code","metadata":{"id":"kq6q-mBbdf3j"},"source":["for i in range(1,6):\n","    print('Test-Run ',i)\n","    print('------------------------------')\n","    print('------------------------------')\n","    model = RandomForestRegressor(n_estimators=100)\n","    model.fit(x_train, y_train)\n","\n","    y_train_pred = model.predict(x_train)\n","    y_vali_pred = model.predict(x_vali)\n","    y_test_pred = model.predict(x_test)\n","\n","    print(\"RF train RMSE: %0.3f\" % sqrt(mean_squared_error(y_train, y_train_pred)))\n","    print(\"RF valid. RMSE: %0.3f\" % sqrt(mean_squared_error(y_vali, y_vali_pred)))\n","    print(\"RF test. RMSE: %0.3f\" % sqrt(mean_squared_error(y_test, y_test_pred)))\n","    print(\"RF test. MAPE: %0.4f\" % (mean_absolute_percentage_error(y_test, y_test_pred)))\n","\n","    print('------------------------------')\n","    print('------------------------------')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gVFAYm1xSR3l"},"source":["#### 24 Hour Sequence Prediction"]},{"cell_type":"code","metadata":{"id":"n3LXrUSdSUNp"},"source":["# Get sliding window for 24 hour prediction\n","window_size = 48\n","flatten = True\n","output_window_size = 24\n","perform_feature_shift = False\n","\n","# Sliding windows\n","# note that the function removes the 'Date' column (not numeric)\n","x_train, y_train = sliding_windows(df=train_df, window_size=window_size, target_column=target_column, flatten=flatten, output_window_size=output_window_size, perform_feature_shift=perform_feature_shift)\n","x_vali, y_vali = sliding_windows(df=vali_df, window_size=window_size, target_column=target_column, flatten=flatten, output_window_size=output_window_size, perform_feature_shift=perform_feature_shift)\n","x_test, y_test = sliding_windows(df=test_df, window_size=window_size, target_column=target_column, flatten=flatten, output_window_size=output_window_size, perform_feature_shift=perform_feature_shift)\n","\n","# Adjust target vectors, keep only last element\n","y_train = y_train[:, -1]\n","y_vali = y_vali[:, -1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j0l4SxLSSUH9"},"source":["# Train random forest\n","model = RandomForestRegressor(n_estimators=500)\n","# model = RandomForestRegressor(n_estimators=100, min_samples_split=3, min_samples_leaf=2, max_depth=50)\n","\n","model.fit(x_train, y_train)\n","\n","# R2 score\n","print(\"RF train R^2-Score: %0.3f\" % model.score(x_train, y_train))\n","print(\"RF valid. R^2-Score: %0.3f\" % model.score(x_vali, y_vali))\n","\n","# RMSE (scaled, if applicable)\n","y_train_pred = model.predict(x_train)\n","y_vali_pred = model.predict(x_vali)\n","\n","print(\"RF train RMSE: %0.3f\" % sqrt(mean_squared_error(y_train_pred, y_train)))\n","print(\"RF valid. RMSE: %0.3f\" % sqrt(mean_squared_error(y_vali_pred, y_vali)))\n","\n","if scaler is not None:\n","  y_train_unscaled = target_scaler.inverse_transform(y_train)\n","  y_vali_unscaled = target_scaler.inverse_transform(y_vali)\n","  y_train_pred_unscaled = target_scaler.inverse_transform(y_train_pred.reshape(-1, 1))\n","  y_vali_pred_unscaled = target_scaler.inverse_transform(y_vali_pred.reshape(-1, 1))\n","  print(\"RF train RMSE (unscaled): %0.3f\" % sqrt(mean_squared_error(y_train_pred_unscaled, y_train_unscaled)))\n","  print(\"RF valid. RMSE (unscaled): %0.3f\" % sqrt(mean_squared_error(y_vali_pred_unscaled, y_vali_unscaled)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U7ZWc5tASUDX"},"source":["# Plot Performance\n","samples = [4,81,854,1701,3621]\n","for i in samples:\n","  plt.figure(figsize=(10,2))\n","  plt.plot(y_vali_pred[i], label='pred')\n","  plt.plot(y_vali[i], label='true')\n","  plt.legend()\n","  plt.xlabel('hours')\n","  plt.ylabel('Demand in MW')\n","  plt.title('Random Forest prediction example on validation set')\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FsoI-emxcBxU"},"source":["##### Testing"]},{"cell_type":"code","metadata":{"id":"iXvGJorSfH4f"},"source":["for i in range(1,6):\n","    print('Test-Run ',i)\n","    print('------------------------------')\n","    print('------------------------------')\n","    model = RandomForestRegressor(n_estimators=100)\n","    model.fit(x_train, y_train)\n","\n","    y_train_pred = model.predict(x_train)\n","    y_vali_pred = model.predict(x_vali)\n","    y_test_pred = model.predict(x_test)\n","\n","    print(\"RF train RMSE: %0.3f\" % sqrt(mean_squared_error(y_train, y_train_pred)))\n","    print(\"RF valid. RMSE: %0.3f\" % sqrt(mean_squared_error(y_vali, y_vali_pred)))\n","    print(\"RF test. RMSE: %0.3f\" % sqrt(mean_squared_error(y_test, y_test_pred)))\n","    print(\"RF test. MAPE: %0.4f\" % (mean_absolute_percentage_error(y_test, y_test_pred)))\n","\n","    print('------------------------------')\n","    print('------------------------------')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y47bMrBoTTZ4"},"source":["#### 24Hour AutoRegressive\n","The 24Hour AutoRegressive Model for random forest is based on the 1H model."]},{"cell_type":"code","metadata":{"id":"I-bmc_1gV-I0"},"source":["# Prepare Sliding Window for 1H Prediction\n","window_size = 18\n","flatten = True\n","output_window_size = 1\n","perform_feature_shift = False\n","\n","# Sliding windows\n","# note that the function removes the 'Date' column (not numeric)\n","x_train, y_train = sliding_windows(df=train_df, window_size=window_size, target_column=target_column, flatten=flatten, output_window_size=output_window_size, perform_feature_shift=perform_feature_shift)\n","x_vali, y_vali = sliding_windows(df=vali_df, window_size=window_size, target_column=target_column, flatten=flatten, output_window_size=output_window_size, perform_feature_shift=perform_feature_shift)\n","x_test, y_test = sliding_windows(df=test_df, window_size=window_size, target_column=target_column, flatten=flatten, output_window_size=output_window_size, perform_feature_shift=perform_feature_shift)\n","\n","# Adjust target vectors, keep only last element\n","y_train = y_train[:, -1]\n","y_vali = y_vali[:, -1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wcff_0tyST_u"},"source":["# Train random forest\n","model = RandomForestRegressor(n_estimators=100)\n","# model = RandomForestRegressor(n_estimators=100, min_samples_split=3, min_samples_leaf=2, max_depth=50)\n","\n","model.fit(x_train, y_train)\n","\n","# R2 score\n","print(\"RF train R^2-Score: %0.3f\" % model.score(x_train, y_train))\n","print(\"RF valid. R^2-Score: %0.3f\" % model.score(x_vali, y_vali))\n","\n","# RMSE (scaled, if applicable)\n","y_train_pred = model.predict(x_train)\n","y_vali_pred = model.predict(x_vali)\n","\n","print(\"RF train RMSE: %0.3f\" % sqrt(mean_squared_error(y_train_pred, y_train)))\n","print(\"RF valid. RMSE: %0.3f\" % sqrt(mean_squared_error(y_vali_pred, y_vali)))\n","\n","if scaler is not None:\n","  y_train_unscaled = target_scaler.inverse_transform(y_train)\n","  y_vali_unscaled = target_scaler.inverse_transform(y_vali)\n","  y_train_pred_unscaled = target_scaler.inverse_transform(y_train_pred.reshape(-1, 1))\n","  y_vali_pred_unscaled = target_scaler.inverse_transform(y_vali_pred.reshape(-1, 1))\n","\n","  # for i in range(len(y_train_pred_unscaled)):\n","    # print(y_vali_unscaled[i], y_vali_pred_unscaled[i])\n","\n","  # print(y_train_unscaled.shape)\n","  # print(y_vali_unscaled.shape)\n","  # print(y_train_pred_unscaled.shape)\n","  # print(y_vali_pred_unscaled.shape)\n","\n","  print(\"RF train RMSE (unscaled): %0.3f\" % sqrt(mean_squared_error(y_train_pred_unscaled, y_train_unscaled)))\n","  print(\"RF valid. RMSE (unscaled): %0.3f\" % sqrt(mean_squared_error(y_vali_pred_unscaled, y_vali_unscaled)))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LaZLUVSLTWN7"},"source":["# Autoregressive predictions\n","pred_length = 24  # number of steps done per prediction\n","dataset = vali_df.copy()  # define dataset (before sliding window)\n","dataset.drop(columns='Date', inplace=True)\n","dataset[target_column] = dataset.pop(target_column)\n","dataset = dataset.to_numpy()\n","\n","# Create dataframe to store losses\n","loss_df = pd.DataFrame(columns=[j for j in range(1, pred_length+1)])\n","# loss_unscaled_df = pd.DataFrame(columns=[j for j in range(1, pred_length+1)])\n","\n","true_values = []\n","\n","for i in range(dataset.shape[0] - window_size - pred_length+1):\n","  # Get first query for each sequence\n","  query = dataset[i:i+window_size].reshape(dataset.shape[1]*window_size)\n","  # print(query)\n","  for j in range(pred_length):\n","    # Predict\n","    pred = model.predict(query.reshape(1,-1))\n","\n","    # Extract true value + additional data from next row\n","    next_row = dataset[i+j+window_size:i+j+window_size+1]\n","    true_value = next_row[:,-1]\n","    additional_data = next_row[:,:-1][0]\n","\n","    # Compute loss and add to dataframes\n","    loss = mean_squared_error(pred, true_value)\n","    # loss_unscaled = mean_squared_error(scaler.inverse_transform(pred), scaler.inverse_transform(true_value))\n","    loss_df.loc[i, j+1] = loss\n","    # loss_unscaled_df.loc[i, j+1] = loss_unscaled\n","\n","    # Get true value of last time step\n","    if j == (pred_length-1):\n","      true_values.append(true_value)\n","\n","    # Create new query window from data + prediction\n","    new_row = np.concatenate((additional_data, pred),axis=None)\n","    query = np.concatenate((query[dataset.shape[1]:], new_row), axis=None)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i4zgEyTlTWJk"},"source":["# GET SQUAREROOT OF VALUES\n","# CURRENTLY REPORTING MSE BELOW\n","\n","# Plot results\n","plt.title('Random Forest autoregressive error')\n","plt.ylabel('MSE')\n","plt.xlabel('Forecasted time-steps')\n","plt.plot(loss_df.mean())\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8Mx5EAnacFNQ"},"source":["##### Testing"]},{"cell_type":"code","metadata":{"id":"-P92a5MscF_-"},"source":["for i in range(1,6):\n","    print('Test-Run ',i)\n","    print('------------------------------')\n","    print('------------------------------')\n","    model = RandomForestRegressor(n_estimators=100)\n","    model.fit(x_train, y_train)\n","\n","    y_train_pred = model.predict(x_train)\n","    y_vali_pred = model.predict(x_vali)\n","    y_test_pred = model.predict(x_test)\n","\n","    print(\"RF train RMSE: %0.3f\" % sqrt(mean_squared_error(y_train, y_train_pred)))\n","    print(\"RF valid. RMSE: %0.3f\" % sqrt(mean_squared_error(y_vali, y_vali_pred)))\n","    print(\"RF test. RMSE: %0.3f\" % sqrt(mean_squared_error(y_test, y_test_pred)))\n","    print(\"RF test. MAPE: %0.4f\" % (mean_absolute_percentage_error(y_test, y_test_pred)))\n","\n","\n","\n","    # Create dataframe to store losses\n","    loss_df = pd.DataFrame(columns=[j for j in range(1, pred_length + 1)])\n","    loss_mape_df = pd.DataFrame(columns=[j for j in range(1, pred_length+1)])\n","\n","    true_values = []\n","\n","    for i in range(dataset.shape[0] - window_size - pred_length + 1):\n","        # Get first query for each sequence\n","        query = dataset[i:i + window_size].reshape(dataset.shape[1] * window_size)\n","        # print(query)\n","        for j in range(pred_length):\n","            # Predict\n","            pred = model.predict(query.reshape(1, -1))\n","\n","            # Extract true value + additional data from next row\n","            next_row = dataset[i + j + window_size:i + j + window_size + 1]\n","            true_value = next_row[:, -1]\n","            additional_data = next_row[:, :-1][0]\n","\n","            # Compute loss and add to dataframes\n","            loss = mean_squared_error(true_value, pred)\n","            loss_mape = mean_absolute_percentage_error(true_value, pred)\n","            # loss_unscaled = mean_squared_error(scaler.inverse_transform(pred), scaler.inverse_transform(true_value))\n","            loss_df.loc[i, j + 1] = loss\n","            loss_mape_df.loc[i, j + 1] = loss_mape\n","            # loss_unscaled_df.loc[i, j+1] = loss_unscaled\n","\n","            # Get true value of last time step\n","            if j == (pred_length - 1):\n","                true_values.append(true_value)\n","\n","            # Create new query window from data + prediction\n","            new_row = np.concatenate((additional_data, pred), axis=None)\n","            query = np.concatenate((query[dataset.shape[1]:], new_row), axis=None)\n","\n","    print('Sequence RMSE: {:.3f}'.format(sqrt(loss_df.mean().mean())))\n","    print('Sequence MAPE: {:.4f}'.format(loss_mape_df.mean().mean()))\n","\n","    print('------------------------------')\n","    print('------------------------------')"],"execution_count":null,"outputs":[]}]}